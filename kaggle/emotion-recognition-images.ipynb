{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1351797,"sourceType":"datasetVersion","datasetId":786787},{"sourceId":4335759,"sourceType":"datasetVersion","datasetId":2552913}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# !pip install -U upgrade pip\n# !pip install -q pytorch_lightning\n# !pip install -q ipywidgets\n# !pip install ultralytics","metadata":{"execution":{"iopub.status.busy":"2024-04-15T13:42:39.463213Z","iopub.execute_input":"2024-04-15T13:42:39.463874Z","iopub.status.idle":"2024-04-15T13:42:39.467607Z","shell.execute_reply.started":"2024-04-15T13:42:39.463837Z","shell.execute_reply":"2024-04-15T13:42:39.466588Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import pytorch_lightning as pl\nfrom pytorch_lightning import Trainer\nfrom pytorch_lightning.callbacks import EarlyStopping\n\nfrom torch import nn, optim\nfrom torch.optim.lr_scheduler import StepLR\nimport torch \nfrom torch.utils.data import DataLoader, Subset, Dataset, random_split\n\nfrom torchvision.models.efficientnet import EfficientNet_V2_S_Weights\nfrom torchvision.transforms.functional import InterpolationMode, to_tensor\nfrom torchvision import models, transforms, datasets\nfrom torchvision import datasets, transforms\n\nimport torchmetrics\nfrom torchmetrics import ConfusionMatrix, Precision, Recall, F1Score\n\nfrom collections import Counter\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport io\nfrom PIL import Image","metadata":{"execution":{"iopub.status.busy":"2024-04-15T13:42:39.469600Z","iopub.execute_input":"2024-04-15T13:42:39.469883Z","iopub.status.idle":"2024-04-15T13:42:50.435515Z","shell.execute_reply.started":"2024-04-15T13:42:39.469860Z","shell.execute_reply":"2024-04-15T13:42:50.434698Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Ajuste de carpeta no utilizada\n\n# # Copiar a directorio de trabajo \n# !cp -a /kaggle/input/young-affectnet-hq /kaggle/working/young-affectnet-hq\n# # Eliminar la carpeta contempt del directorio copiado (conservando el resto)\n# !rm -r /kaggle/working/young-affectnet-hq/contempt\n# # Cambiar el nombre de la carpeta anger por angry\n# !mv /kaggle/working/young-affectnet-hq/anger /kaggle/working/young-affectnet-hq/angry\n\nimport os\nimport shutil\n\n# Directorio fuente y destino\nsource_dir = \"/kaggle/input/young-affectnet-hq\"\ntarget_dir = \"/kaggle/working/young-affectnet-hq\"\n\n# Comprobar si el directorio ya ha sido copiado\nif not os.path.exists(target_dir):\n    # Copiar el directorio\n    shutil.copytree(source_dir, target_dir)\n    print(f\"Directorio copiado: {target_dir}\")\nelse:\n    print(f\"El directorio ya existe: {target_dir}\")\n\n# Comprobar si la carpeta 'contempt' existe y eliminarla\ncontempt_dir = os.path.join(target_dir, \"contempt\")\nif os.path.exists(contempt_dir):\n    shutil.rmtree(contempt_dir)\n    print(f\"Carpeta eliminada: {contempt_dir}\")\nelse:\n    print(f\"La carpeta no existe o ya fue eliminada: {contempt_dir}\")\n\n# Comprobar si la carpeta 'anger' necesita ser renombrada a 'angry'\nanger_dir = os.path.join(target_dir, \"anger\")\nangry_dir = os.path.join(target_dir, \"angry\")\n\nif os.path.exists(anger_dir) and not os.path.exists(angry_dir):\n    os.rename(anger_dir, angry_dir)\n    print(f\"Carpeta renombrada de 'anger' a 'angry'\")\nelse:\n    if not os.path.exists(anger_dir):\n        print(\"La carpeta 'anger' no existe.\")\n    if os.path.exists(angry_dir):\n        print(\"La carpeta 'angry' ya existe.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-04-15T13:42:50.436605Z","iopub.execute_input":"2024-04-15T13:42:50.437034Z","iopub.status.idle":"2024-04-15T13:45:36.236094Z","shell.execute_reply.started":"2024-04-15T13:42:50.437008Z","shell.execute_reply":"2024-04-15T13:45:36.235116Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Directorio copiado: /kaggle/working/young-affectnet-hq\nCarpeta eliminada: /kaggle/working/young-affectnet-hq/contempt\nCarpeta renombrada de 'anger' a 'angry'\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Creacion de los datamodules ","metadata":{}},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(self, subset, transform=None):\n        self.subset = subset\n        self.transform = transform\n\n    def __getitem__(self, index):\n        x, y = self.subset[index]\n        if self.transform:\n            x = self.transform(x)\n        return x, y\n\n    def __len__(self):\n        return len(self.subset)\n    \ndef get_weights(dataset_path):\n    class_counts = {}\n    for clase in os.listdir(f'{dataset_path}'):\n        class_counts[clase] = len(os.listdir(f'{dataset_path}/{clase}'))\n        \n    # Total de muestras\n    total_samples = sum(class_counts.values())\n\n    # Calcular los pesos inversos de la frecuencia de las clases\n    class_weights = {cls: total_samples / count for cls, count in class_counts.items()}\n\n    # Normalizar los pesos para que el menor sea 1.0\n    min_weight = min(class_weights.values())\n    normalized_weights = {cls: weight / min_weight for cls, weight in class_weights.items()}\n\n    # Convertir los pesos a un tensor para usar en PyTorch\n    weights_tensor = torch.tensor(list(normalized_weights.values()), dtype=torch.float32)\n\n    return weights_tensor","metadata":{"execution":{"iopub.status.busy":"2024-04-15T13:45:36.237422Z","iopub.execute_input":"2024-04-15T13:45:36.237819Z","iopub.status.idle":"2024-04-15T13:45:36.247050Z","shell.execute_reply.started":"2024-04-15T13:45:36.237767Z","shell.execute_reply":"2024-04-15T13:45:36.246107Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## Fer2013 datamodule","metadata":{}},{"cell_type":"code","source":"class FER2013DataModule(pl.LightningDataModule):\n    def __init__(self, train_dir: str, test_dir: str, batch_size: int = 128):\n        super().__init__()\n        \n        self.train_dir = train_dir\n        self.test_dir = test_dir\n        self.batch_size = batch_size\n        \n        self.train_transforms = transforms.Compose([\n            transforms.Resize(256, interpolation=InterpolationMode.BILINEAR),\n            transforms.CenterCrop(224),\n            transforms.Grayscale(num_output_channels=3),  # Convert 1 channel grayscale to 3 channel grayscale\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n        ])\n        \n        self.val_transforms = transforms.Compose([\n            transforms.Resize(256, interpolation=InterpolationMode.BILINEAR),\n            transforms.CenterCrop(224),\n            transforms.Grayscale(num_output_channels=3),  # Convert 1 channel grayscale to 3 channel grayscale\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n        ])\n        \n        self.test_transforms = transforms.Compose([\n            transforms.Resize(256, interpolation=InterpolationMode.BILINEAR),\n            transforms.CenterCrop(224),\n            transforms.Grayscale(num_output_channels=3),  # Convert 1 channel grayscale to 3 channel grayscale\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n        ])\n\n    def setup(self, stage: str = None):\n        if stage == 'fit' or stage is None:\n            full_dataset = datasets.ImageFolder(self.train_dir)\n            train_size = int(0.85 * len(full_dataset))\n            val_size = len(full_dataset) - train_size\n    \n            train_indices, val_indices = random_split(range(len(full_dataset)), \n                                                      [train_size, val_size], \n                                                      generator=torch.Generator().manual_seed(42))\n            \n            train_subset = Subset(full_dataset, train_indices)\n            val_subset = Subset(full_dataset, val_indices)\n            \n            self.train_ds = CustomDataset(train_subset, transform=self.train_transforms)\n            self.val_ds = CustomDataset(val_subset, transform=self.val_transforms)\n\n        if stage == 'test' or stage is None:\n            self.test_ds = datasets.ImageFolder(self.test_dir, transform=self.test_transforms)\n    \n    def get_n_classes(self):\n        return len(self.full_dataset.classes)\n    \n    def get_weights(self):\n        # Calcular y retornar los pesos de las clases\n        return get_weights(self.train_dir)\n    \n    def train_dataloader(self):\n        return DataLoader(self.train_ds, batch_size=self.batch_size, shuffle=True, num_workers=4)\n\n    def val_dataloader(self):\n        return DataLoader(self.val_ds, batch_size=self.batch_size, shuffle=False, num_workers=4)\n\n    def test_dataloader(self):\n        return DataLoader(self.test_ds, batch_size=self.batch_size, shuffle = False, num_workers=4)\n    \n    \n# fer2013_ds = FER2013DataModule(train_dir = '/kaggle/input/fer2013/train', test_dir = '/kaggle/input/fer2013/test', batch_size = 64)","metadata":{"execution":{"iopub.status.busy":"2024-04-15T13:45:36.250273Z","iopub.execute_input":"2024-04-15T13:45:36.250708Z","iopub.status.idle":"2024-04-15T13:45:38.059145Z","shell.execute_reply.started":"2024-04-15T13:45:36.250676Z","shell.execute_reply":"2024-04-15T13:45:38.058184Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## Young affectnet hq ","metadata":{}},{"cell_type":"code","source":"class YoungAffectNetDataModule(pl.LightningDataModule):\n    def __init__(self, imgs_dir: str, batch_size: int = 128):\n        super().__init__()\n        self.imgs_dir = imgs_dir\n        self.batch_size = batch_size\n        \n        self.full_dataset = None\n        self.train_ds = None\n        self.val_ds = None\n        self.test_ds = None\n        \n        self.train_transforms = transforms.Compose([\n#             transforms.RandomResizedCrop(224),\n#             transforms.RandomHorizontalFlip(),\n            transforms.Resize(256),\n            transforms.CenterCrop(224),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n        ])\n        \n        self.val_transforms = transforms.Compose([\n            transforms.Resize(256),\n            transforms.CenterCrop(224),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n        ])\n        \n    def prepare_data(self):\n        self.full_dataset = datasets.ImageFolder(self.imgs_dir)\n        train_size = int(0.7 * len(self.full_dataset))\n        val_size = int(0.2 * len(self.full_dataset))\n        test_size = len(self.full_dataset) - train_size - val_size\n\n        self.train_indices, self.val_indices, self.test_indices = random_split(\n            range(len(self.full_dataset)), \n            [train_size, val_size, test_size], \n            generator=torch.Generator().manual_seed(42)\n        )\n\n\n    def setup(self, stage: str = None):\n        if not self.full_dataset:\n            self.prepare_data() \n            \n        if stage == 'fit' or stage is None:\n            train_subset = Subset(self.full_dataset, self.train_indices)\n            val_subset = Subset(self.full_dataset, self.val_indices)\n            \n            self.train_ds = CustomDataset(train_subset, transform=self.train_transforms)\n            self.val_ds = CustomDataset(val_subset, transform=self.val_transforms)\n            \n        if stage == 'test' or stage is None:\n            test_subset = Subset(self.full_dataset, self.test_indices)\n            self.test_ds = CustomDataset(test_subset, transform=self.val_transforms)\n    \n    def get_weights(self):\n        if not self.full_dataset:\n            self.prepare_data()\n        \n        # Calcular y retornar los pesos de las clases\n        return get_weights(self.imgs_dir)\n    \n    def get_n_classes(self):\n        print(self.full_dataset.classes)\n        return len(self.full_dataset.classes)\n    \n    def train_dataloader(self):\n        return DataLoader(self.train_ds, batch_size=self.batch_size, shuffle=True, num_workers=4)\n\n    def val_dataloader(self):\n        return DataLoader(self.val_ds, batch_size=self.batch_size, shuffle=False, num_workers=4)\n\n    def test_dataloader(self):\n        return DataLoader(self.test_ds, batch_size=self.batch_size, shuffle=False, num_workers=4)\n\n    \n# Luego, para usarlo en el entrenador:\n# young_affectnet_ds = YoungAffectNetDataModule(imgs_dir='/kaggle/working/young-affectnet-hq', batch_size = 64)\n# young_affectnet_ds.setup(\"fit\")\n# young_affectnet_ds.get_n_classes()","metadata":{"execution":{"iopub.status.busy":"2024-04-15T13:45:38.060393Z","iopub.execute_input":"2024-04-15T13:45:38.060724Z","iopub.status.idle":"2024-04-15T13:45:38.078157Z","shell.execute_reply.started":"2024-04-15T13:45:38.060688Z","shell.execute_reply":"2024-04-15T13:45:38.077392Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"class FaceEmotionClassifier(pl.LightningModule):\n    def __init__(self, model_name, num_classes=7, learning_rate=0.00001, pretrained = True, weights = None):\n        super().__init__()\n        \n        assert model_name in ['efficientnet_b6', 'resnet50', 'mobilenet_v3_small', 'mobilenet_v3_large', 'efficientnet_v2_s']\n        \n        pretrained_imagenet = 'IMAGENET1K_V1' if pretrained else None\n        \n        if model_name == 'efficientnet_b6':\n            self.model = models.efficientnet_b6(weights=pretrained_imagenet)\n            \n#             for param in self.model.parameters():\n#                 param.requires_grad = False\n            \n            self.model.classifier[1] = nn.Linear(self.model.classifier[1].in_features, num_classes)\n        \n        if model_name == 'mobilenet_v3_small':\n            self.model = models.mobilenet_v3_small(weights=pretrained_imagenet)\n                        \n#             for param in self.model.parameters():\n#                 param.requires_grad = False\n            \n            self.model.classifier[3] = nn.Linear(self.model.classifier[3].in_features, num_classes)\n        \n        elif model_name == 'mobilenet_v3_large':\n            self.model = models.mobilenet_v3_large(weights=pretrained_imagenet)\n            \n#             for param in self.model.parameters():\n#                 param.requires_grad = False\n            \n            self.model.classifier[3] = nn.Linear(self.model.classifier[3].in_features, num_classes)\n        \n        elif model_name == 'efficientnet_v2_s':\n            self.model = models.efficientnet_v2_s(weights=pretrained_imagenet)\n            \n#             for param in self.model.parameters():\n#                 param.requires_grad = False\n            \n            self.model.classifier[1] = nn.Linear(self.model.classifier[1].in_features, num_classes)\n        \n        elif model_name == 'resnet50':\n            self.model = models.resnet50(weights=pretrained_imagenet)\n#           (fc): Linear(in_features=2048, out_features=1000, bias=True)\n            self.model.fc = nn.Linear(self.model.fc.in_features, num_classes)\n            \n            \n        self.criterion = nn.CrossEntropyLoss(weight=weights)\n        self.learning_rate = learning_rate\n        # Metrics\n        self.train_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes)\n        self.val_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes)\n        self.test_acc = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes)\n        \n        self.train_precision = torchmetrics.Precision(task=\"multiclass\", average='micro', num_classes=num_classes)\n#         self.val_precision = torchmetrics.Precision(task=\"multiclass\", average='micro', num_classes=num_classes)\n        self.test_precision = torchmetrics.Precision(task=\"multiclass\", average='micro', num_classes=num_classes)\n        \n        self.train_recall = torchmetrics.Recall(task=\"multiclass\", average='micro', num_classes=num_classes)\n#         self.val_recall = torchmetrics.Recall(task=\"multiclass\", average='micro', num_classes=num_classes)\n        self.test_recall = torchmetrics.Recall(task=\"multiclass\", average='micro', num_classes=num_classes)\n        \n        self.train_f1 = torchmetrics.F1Score(task=\"multiclass\", num_classes=num_classes)\n#         self.val_f1 = torchmetrics.F1Score(task=\"multiclass\", num_classes=num_classes)\n        self.test_f1 = torchmetrics.F1Score(task=\"multiclass\", num_classes=num_classes)\n        \n\n    def forward(self, x):\n        return self.model(x)\n\n    def training_step(self, batch, batch_idx):\n        images, labels = batch\n        outputs = self(images)\n        loss = self.criterion(outputs, labels)\n        preds = torch.argmax(outputs, dim=1)\n        acc = self.train_acc(preds, labels)\n        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n        self.log('train_acc', acc, on_step=True, on_epoch=True, prog_bar=True)\n        return loss\n\n    def validation_step(self, batch, batch_idx):\n        images, labels = batch\n        outputs = self(images)\n        loss = self.criterion(outputs, labels)\n        preds = torch.argmax(outputs, dim=1)\n        acc = self.val_acc(preds, labels)\n        self.log('val_loss', loss, on_step=False, on_epoch=True, prog_bar=True)\n        self.log('val_acc', acc, on_step=False, on_epoch=True, prog_bar=True)\n        return loss\n\n    def test_step(self, batch, batch_idx):\n        images, labels = batch\n        outputs = self(images)\n        loss = self.criterion(outputs, labels)\n        preds = torch.argmax(outputs, dim=1)\n        acc = self.test_acc(preds, labels)\n        # Update metrics\n        self.test_precision.update(preds, labels)\n        self.test_recall.update(preds, labels)\n        self.test_f1.update(preds, labels)\n        self.log('test_loss', loss, on_epoch=True, prog_bar=True)\n        self.log('test_acc', acc, on_epoch=True, prog_bar=True)\n        return loss\n\n    def on_test_epoch_end(self):\n        # Log the confusion matrix and other metrics at the end of the test\n        self.log('precision', self.test_precision.compute())\n        self.log('recall', self.test_recall.compute())\n        self.log('f1_score', self.test_f1.compute())\n        # Reset metrics\n       \n        self.test_precision.reset()\n        self.test_recall.reset()\n        self.test_f1.reset()\n        \n\n    def configure_optimizers(self):\n        optimizer = optim.Adam(self.parameters(), lr=self.learning_rate)\n        lr_scheduler = {\n                'scheduler': StepLR(optimizer, step_size=5, gamma=0.1),\n                'name': 'learning_rate',\n                'interval': 'epoch',  # 'step' para actualizar cada paso, 'epoch' para cada época\n                'frequency': 1,  # Frecuencia de actualización\n            }\n        return [optimizer], [lr_scheduler]\n    \n    def print_model(self):\n        print(self.model)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-15T13:45:38.079477Z","iopub.execute_input":"2024-04-15T13:45:38.079823Z","iopub.status.idle":"2024-04-15T13:45:38.105050Z","shell.execute_reply.started":"2024-04-15T13:45:38.079772Z","shell.execute_reply":"2024-04-15T13:45:38.104245Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# fer2013_data_module = FER2013DataModule(train_dir = '/kaggle/input/fer2013/train', test_dir = '/kaggle/input/fer2013/test', batch_size = 32)\naffectnet_data_module = YoungAffectNetDataModule(imgs_dir='/kaggle/working/young-affectnet-hq', \n                                                 batch_size = 1)\nweights = affectnet_data_module.get_weights()\n\nresults = dict()\n\nmodel_name_list = ['mobilenet_v3_small'] # 'mobilenet_v3_large', 'resnet50', 'mobilenet_v3_small', 'efficientnet_v2_s']\nfor model_name in model_name_list:\n    \n    \n    model = FaceEmotionClassifier(model_name = model_name, num_classes = 7, learning_rate=0.0001, pretrained=True, weights = weights)\n#     model.print_model()\n    early_stopping = EarlyStopping(\n        monitor='val_loss',  # Métrica a monitorear\n        patience=5,  # Número de épocas sin mejora después de las cuales se detendrá el entrenamiento\n        verbose=True,  # Para loggear cuando se detiene el entrenamiento\n        mode='min',  # 'min' si la métrica debe disminuir (para pérdida), 'max' para métricas como la precisión\n    )\n\n    trainer = Trainer(min_epochs = 2,  \n                      max_epochs = 10, \n                      devices=1, \n                      accelerator='gpu', \n                      callbacks = [early_stopping])#'gpu'\n    print(f'Training {model_name}...')\n    # Train the model\n    trainer.fit(model, datamodule=affectnet_data_module)\n    print(f'Testing {model_name}...')\n    # Evaluate the model on the test set\n    trainer.test(model, datamodule=affectnet_data_module)\n\n    \n    \n    \n    # Save the fine-tuned model\n# trainer.save_checkpoint(\"/kaggle/working/fine_tuned_mobilenet_v3_small.ckpt\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Results obtained\")\n## FER2013\n# Mobilenet V3 Large:\n\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃        Test metric        ┃       DataLoader 0        ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│         f1_score          │    0.6054611206054688     │\n│         precision         │    0.6054611206054688     │\n│          recall           │    0.6054611206054688     │\n│         test_acc          │    0.6054611206054688     │\n│         test_loss         │    1.3348348140716553     │\n└───────────────────────────┴───────────────────────────┘\n\n# Mobilenet V3 Small:\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃        Test metric        ┃       DataLoader 0        ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│         f1_score          │    0.5653385519981384     │\n│         precision         │    0.5653385519981384     │\n│          recall           │    0.5653385519981384     │\n│         test_acc          │    0.5653385519981384     │\n│         test_loss         │    1.2770402431488037     │\n└───────────────────────────┴───────────────────────────┘\n\n# Resnet 50:\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃        Test metric        ┃       DataLoader 0        ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│         f1_score          │    0.6518529057502747     │\n│         precision         │    0.6518529057502747     │\n│          recall           │    0.6518529057502747     │\n│         test_acc          │    0.6518529057502747     │\n│         test_loss         │     1.244256615638733     │\n└───────────────────────────┴───────────────────────────┘\n\n# Efficientnet V2 S:\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃        Test metric        ┃       DataLoader 0        ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│         f1_score          │    0.6779047250747681     │\n│         precision         │    0.6779047250747681     │\n│          recall           │    0.6779047250747681     │\n│         test_acc          │    0.6779047250747681     │\n│         test_loss         │     1.244596004486084     │\n└───────────────────────────┴───────────────────────────┘\n\n## AffectNet\n# Mobilenet V3 Large:\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃        Test metric        ┃       DataLoader 0        ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│         f1_score          │    0.6053042411804199     │\n│         precision         │    0.6053042411804199     │\n│          recall           │    0.6053042411804199     │\n│         test_acc          │    0.6053042411804199     │\n│         test_loss         │     1.154691219329834     │\n└───────────────────────────┴───────────────────────────┘\n\n# Mobilenet V3 Small:\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃        Test metric        ┃       DataLoader 0        ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│         f1_score          │    0.5811232328414917     │\n│         precision         │    0.5811232328414917     │\n│          recall           │    0.5811232328414917     │\n│         test_acc          │    0.5811232328414917     │\n│         test_loss         │    1.0759913921356201     │\n└───────────────────────────┴───────────────────────────┘\n\n# Resnet 50:\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃        Test metric        ┃       DataLoader 0        ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│         f1_score          │    0.6560062170028687     │\n│         precision         │    0.6560062170028687     │\n│          recall           │    0.6560062170028687     │\n│         test_acc          │    0.6560062170028687     │\n│         test_loss         │    1.2396374940872192     │\n└───────────────────────────┴───────────────────────────┘\n\n# Efficientnet V2 S:\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃        Test metric        ┃       DataLoader 0        ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n│         f1_score          │    0.6779047250747681     │\n│         precision         │    0.6779047250747681     │\n│          recall           │    0.6779047250747681     │\n│         test_acc          │    0.6779047250747681     │\n│         test_loss         │     1.244596004486084     │\n└───────────────────────────┴───────────────────────────┘","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}